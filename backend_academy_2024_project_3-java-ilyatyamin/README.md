## ДЗ-3. Академия Бэкенда 23/24

### Илья Тямин, tg [@mrshrimp_it](https://t.me/mrshrimp_it)

### Ввод
Для того чтобы запустить проект, необходимо передать некоторые флаги и значения в командную строку:
- Обязательные
    - `--path` -- путь на URL к файлу с nginx-логами или glob-путь к одному/нескольким файлам на локальном диске
- Необязательные
  - `--from` -- дата в формате "YYYY-mm-dd", начиная с которой необходимо фильтровать логи
  - `--to` -- дата в формате "YYYY-mm-dd", заканчивая которой необходимо фильтровать логи
  - `--format` -- одно из двух ['markdown', 'adoc'], как нужно отрендерить отчет. Если не указывать, то будет выбран markdown.
  - `--filter-field` -- название поля, на основании которого также необходимо отсортировать логи. Одно из следующего списка: ["remoteAddress", "remoteUser", "requestMethod", "requestURL", "requestHTTPVersion", "status",
    "bodyBytesSent", "httpReferer", "httpUserAgent"]
  - `--filter-value` -- значение поля, на основании которого также необходимо отсортировать логи. Если не указать его, а указать только filter-field, фильтрация совершена не будет

### Собираемые статистики
Обязательные:
1. Общее количество запросов
2. Наиболее часто запрашиваемый(ые) ресурс
3. Наиболее часто встречаемый(ые) код ответа
4. Средний размер ответа сервера
5. 95% перцентиль размера ответа сервера

Также дополнительно собираются следующие:
- В какой временной интервал чаще всего отсылаются запросы? (0-3 часа, 3-6, ..., 21-23:59)
- Какой самый частый user-agent в запросах

### Примеры работы
Для следующих флагов:
```shell
--path https://raw.githubusercontent.com/elastic/examples/master/Common%20Data%20Formats/nginx_logs/nginx_logs --from 2014-08-31 --format markdown --filter-field status
```

Был сгенерирован следующий отчет [тык](examples/example.md)

А для таких флагов:
```shell
--path https://raw.githubusercontent.com/elastic/examples/master/Common%20Data%20Formats/nginx_logs/nginx_logs --from 2014-08-31 --format markdown --filter-field status --filter-value 404
```
Был сгенерирован вот такой отчет [тык](examples/example2.md)

### Архитектура
Задача проекта -- собрать данные по указанному в командной строке пути, используя либо запрос к сети (HTTP) или собирая все данные по указанному glob-пути. 

В связи с этим есть 2 вида парсеров:
- [FileLogsParser](src/main/java/backend/academy/parsers/FileLogsParser.java), он смотрит на glob-адрес и мерджит все файлы в один стрим. Использую PathMatcher для облегчения своей жизни
- [HttpLogsParser](src/main/java/backend/academy/parsers/HttpLogsParser.java). Он делает запрос к HTTP-ресурсу и с помощью BufferedReader-а лениво получает ответ (не забирает все в память).

Нужный вид парсера выбирается на основании того, что пользователь ввел в командную строку. Если в его вводе присутствует намек на запрос в сеть, то выбирается HttpLogsParser, иначе другой.

Из парсеров возвращается Stream<String>, с которым можно работать дальше

Из строки nginx-лога нужно сделать какой-либо ООП-объект с полями, за это у меня отвечает [LogInstance](src/main/java/backend/academy/record/LogInstance.java) -- сам объект, в котором я храню данные из распарсенной строки, а также [LogRecordParser](LogInstance](src/main/java/backend/academy/record/LogRecordParser.java) -- util-класс со статическим методом, позволяющим распарсить строку с помощью регулярного выражения. 

Обработкой и ядром проекта является класс [ReportComputer](src/main/java/backend/academy/report/ReportComputer.java). Он принимает в себя Stream<String> и проводит все дальнейшие действия для его обработки (map в LogInstance), фильтрует по полю (если пользователь указал его в командной строке), фильтрует по датам (если пользователь указал дату начала и/или дату конца). 

По поводу подсчета статистик: я подумал, что их достаточно большое количество, чтобы считать просто какими-то функциями. Поэтому я каждую из подсчитываемых статистик представил в виде класса, имплементирующего интерфейс `MetricCounter` ([вот тут](src/main/java/backend/academy/metrics/MetricCounter.java)). В свою очередь он реализует интерфейс `Consumer<LogInstance>`. Итого, интерфейс предоставляет контракт с двумя методами:
- accept(LogInstance instance) -- принимает instance и производит промежуточные подсчеты статистики (можно сказать, что это промежуточная операция)
- fill(LogReport report) -- принимает report и проставляет накопленную статистику там (можно сказать, что это терминальная операция).

Итого, пайплайн выглядит так: каждый из логов подается в каждый из MetricCounter, он производит промежуточные вычисления (например, добавляет в подсчитывающую мапу данный объект, или суммирует значения). После того как данных не осталось, вызывается метод fill(), который заносит подсчитанную статистику в репорт.

Классов статистик всего 7, их назначение можно понять по названию ([линк на них](src/main/java/backend/academy/metrics)).

После того как все статистики были подсчитаны, отдается класс [LogReport](src/main/java/backend/academy/report/LogReport.java) -- по факту, дата-класс с созданными статистиками.

Для рендера класса также есть два варианта -- маркдаун и adoc. Они объеденены абстрактным классом [ReportRenderer](src/main/java/backend/academy/render/ReportRenderer.java), был сделан именно он из-за необходимости создания protected-методов.
- [MarkdownRenderer](src/main/java/backend/academy/render/MarkdownRenderer.java) (наследуется от ReportRenderer) -- представляет отчет в формату markdown. **Если пользователь не пишет формат в командной строке, то будет использован именно маркдаун**.
- [AdocRenderer](src/main/java/backend/academy/render/AdocRenderer.java) (наследуется от ReportRenderer) -- представляет отчет в формате adoc

Отчет выводится на экран с помощью OutputHandler-а.

### Мелочи жизни
Для удобного подсчета статистик также сделал класс `FrequencyMap`, он сам в map-е считает, какое значение самое популярное, и может отдать LinkedHashMap в котором все пары ключ-значение отсортированы по возрастанию значения.

### Хорошего вечера!
![](https://s9.travelask.ru/uploads/post/000/025/451/main_image/facebook-de2a086fe0601f435c0bd4e18e69f942.jpg)
